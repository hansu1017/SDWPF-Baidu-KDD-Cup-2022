{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "41cdcf6d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import collections\n",
    "from tqdm import tqdm\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0d4e6eac",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "input_len = 144\n",
    "df = pd.read_csv('data/wtbdata_245days.csv')\n",
    "df = df.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ea97f674",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## drop abnormal samples\n",
    "def drop_abnormal(df_train):\n",
    "    index_list1 = []\n",
    "    ls = list(df_train['Patv_seq'])\n",
    "    for i in range(len(ls)):\n",
    "        n = len([x for x in ls[i] if x<0])\n",
    "        if n>100:\n",
    "            index_list1.append(i)\n",
    "\n",
    "    index_list2 = []\n",
    "    ls = list(df_train['Pab1_seq'])\n",
    "    for i in range(len(ls)):\n",
    "        n = len([x for x in ls[i] if x>89])\n",
    "        if n>100:\n",
    "            index_list2.append(i)\n",
    "\n",
    "    abnormal = list(set(index_list1)|set(index_list2))\n",
    "    ls_new = []\n",
    "    for x in range(len(df_train)):\n",
    "        if x not in abnormal:\n",
    "            ls_new.append(x)\n",
    "            \n",
    "    return df_train.loc[ls_new]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "080b234a",
   "metadata": {},
   "source": [
    "## generate sequences of each turbine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "35a09ca8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for turbid in range(134): \n",
    "    full_dict = collections.defaultdict(list)\n",
    "    turb_data = df[df['TurbID']==turbid+1].reset_index(drop=True)\n",
    "    ls = list(turb_data['Patv'])\n",
    "    for i in range(0, len(ls)-288-input_len):\n",
    "        \n",
    "        full_dict['Wspd_seq'].append(list(turb_data['Wspd'])[i:i+input_len])\n",
    "        full_dict['Patv_seq'].append(list(turb_data['Patv'])[i:i+input_len])\n",
    "        full_dict['Etmp_seq'].append(list(turb_data['Etmp'])[i:i+input_len])\n",
    "        full_dict['Itmp_seq'].append(list(turb_data['Itmp'])[i:i+input_len])\n",
    "        full_dict['Pab1_seq'].append(list(turb_data['Pab1'])[i:i+input_len])      \n",
    "\n",
    "        full_dict['target'].append(list(turb_data['Patv'])[i+input_len:i+input_len+288])\n",
    "\n",
    "    df_his = pd.DataFrame(full_dict)\n",
    "    df_his.to_csv('/data/turbine_data'+str(turbid+1)+'.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0ddb2d4",
   "metadata": {},
   "source": [
    "## get space information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ddb6c971",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 134/134 [00:00<00:00, 968.02it/s]\n"
     ]
    }
   ],
   "source": [
    "df_loc = pd.read_csv('data/sdwpf_baidukddcup2022_turb_location.CSV')\n",
    "\n",
    "dist_dict = {}\n",
    "for i in tqdm(range(134)):\n",
    "    x = float(df_loc[df_loc['TurbID']==i+1]['x'])\n",
    "    y = float(df_loc[df_loc['TurbID']==i+1]['y'])\n",
    "    df_loc['dist'] = np.sqrt((df_loc['x']-x)**2+(df_loc['y']-y)**2)\n",
    "    dist_dict[i+1] = list(df_loc.sort_values('dist', ascending=True)['TurbID'])[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f5b0fbe7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_group = df[['Day','Tmstamp','Patv']].groupby(['Day','Tmstamp'], as_index=False).agg(list)\n",
    "df_group.columns = ['Day','Tmstamp','Patv_list']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f4fbb2c9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "with open('data/dist_dict.pickle', 'wb') as f:\n",
    "    pickle.dump(dist_dict, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa351ed1",
   "metadata": {},
   "source": [
    "## sample data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2c861822",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 134/134 [03:55<00:00,  1.76s/it]\n"
     ]
    }
   ],
   "source": [
    "## seed = 2\n",
    "for i in tqdm(range(134)):\n",
    "    df_tmp = pd.read_csv('data/turbine_data'+str(i+1)+'.csv')\n",
    "    df_tmp['index'] = list(range(len(df_tmp)))\n",
    "    df_tmp = df_tmp.sample(frac=0.01, random_state=2)\n",
    "    index_list = list(df_tmp['index'])\n",
    "    df_tmp['TurbID'] = i+1\n",
    "\n",
    "    turb_data = df[df['TurbID']==i+1].reset_index(drop=True)\n",
    "    near_turbs = dist_dict[i+1][:121]\n",
    "    index_new = [x+144-1 for x in index_list]\n",
    "    selected_df = turb_data.loc[index_new]\n",
    "    selected_df = pd.merge(selected_df, df_group, how='left', on=['Day','Tmstamp'])\n",
    "    selected_df['Patv_space'] = selected_df['Patv_list'].apply(lambda x: [x[k-1] for k in near_turbs])    \n",
    "    df_tmp['Patv_space'] = list(selected_df['Patv_space'])\n",
    "    \n",
    "    \n",
    "    if i==0:\n",
    "        train = df_tmp.copy()\n",
    "    else:\n",
    "        train = pd.concat([train, df_tmp])\n",
    "train = train.reset_index(drop=True)\n",
    "train = train.sample(frac=1, random_state=2).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "759c86b8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cols = [x for x in train.columns if 'seq' in x or x=='target']\n",
    "for col in cols:\n",
    "    train[col] = train[col].apply(lambda x: json.loads(x))\n",
    "    \n",
    "train = drop_abnormal(train)\n",
    "train.to_csv('data/train_data_normal.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0361e611",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 134/134 [02:27<00:00,  1.10s/it]\n"
     ]
    }
   ],
   "source": [
    "## seed = 42\n",
    "for i in tqdm(range(134)):\n",
    "    df_tmp = pd.read_csv('data/turbine_data'+str(i+1)+'.csv')\n",
    "    df_tmp['index'] = list(range(len(df_tmp)))\n",
    "    df_tmp = df_tmp.sample(frac=0.01, random_state=2)\n",
    "    index_list = list(df_tmp['index'])\n",
    "    df_tmp['TurbID'] = i+1\n",
    "\n",
    "    turb_data = df[df['TurbID']==i+1].reset_index(drop=True)\n",
    "    near_turbs = dist_dict[i+1][:121]\n",
    "    index_new = [x+144-1 for x in index_list]\n",
    "    selected_df = turb_data.loc[index_new]\n",
    "    selected_df = pd.merge(selected_df, df_group, how='left', on=['Day','Tmstamp'])\n",
    "    selected_df['Patv_space'] = selected_df['Patv_list'].apply(lambda x: [x[k-1] for k in near_turbs])    \n",
    "    df_tmp['Patv_space'] = list(selected_df['Patv_space'])\n",
    "    \n",
    "    \n",
    "    if i==0:\n",
    "        train = df_tmp.copy()\n",
    "    else:\n",
    "        train = pd.concat([train, df_tmp])\n",
    "train = train.reset_index(drop=True)\n",
    "train = train.sample(frac=1, random_state=2).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "598950a4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cols = [x for x in train.columns if 'seq' in x or x=='target']\n",
    "for col in cols:\n",
    "    train[col] = train[col].apply(lambda x: json.loads(x))\n",
    "    \n",
    "train = drop_abnormal(train)\n",
    "train.to_csv('data/train_data42.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6f6dfdc4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 134/134 [02:28<00:00,  1.11s/it]\n"
     ]
    }
   ],
   "source": [
    "## seed = 2022\n",
    "for i in tqdm(range(134)):\n",
    "    df_tmp = pd.read_csv('data/turbine_data'+str(i+1)+'.csv')\n",
    "    df_tmp['index'] = list(range(len(df_tmp)))\n",
    "    df_tmp = df_tmp.sample(frac=0.01, random_state=2)\n",
    "    index_list = list(df_tmp['index'])\n",
    "    df_tmp['TurbID'] = i+1\n",
    "\n",
    "    turb_data = df[df['TurbID']==i+1].reset_index(drop=True)\n",
    "    near_turbs = dist_dict[i+1][:121]\n",
    "    index_new = [x+144-1 for x in index_list]\n",
    "    selected_df = turb_data.loc[index_new]\n",
    "    selected_df = pd.merge(selected_df, df_group, how='left', on=['Day','Tmstamp'])\n",
    "    selected_df['Patv_space'] = selected_df['Patv_list'].apply(lambda x: [x[k-1] for k in near_turbs])    \n",
    "    df_tmp['Patv_space'] = list(selected_df['Patv_space'])\n",
    "    \n",
    "    \n",
    "    if i==0:\n",
    "        train = df_tmp.copy()\n",
    "    else:\n",
    "        train = pd.concat([train, df_tmp])\n",
    "train = train.reset_index(drop=True)\n",
    "train = train.sample(frac=1, random_state=2).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ba76a900",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cols = [x for x in train.columns if 'seq' in x or x=='target']\n",
    "for col in cols:\n",
    "    train[col] = train[col].apply(lambda x: json.loads(x))\n",
    "    \n",
    "train = drop_abnormal(train)\n",
    "train.to_csv('data/train_data2022.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d445a955",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "py35-paddle1.2.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
